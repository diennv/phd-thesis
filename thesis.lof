\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Surveillance Camera Deployment and Application\relax }}{1}{figure.caption.7}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{1}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{1}{subfigure.1.2}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Overall of cloud based video analytics server\relax }}{2}{figure.caption.8}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Real-time Video Analytics Challenges\relax }}{3}{figure.caption.9}
\contentsline {figure}{\numberline {1.4}{\ignorespaces The motivated system design\relax }}{4}{figure.caption.10}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Video Analytics Implementation, (a) Video management server based implementation, (b) Edge camera based implementation\relax }}{8}{figure.caption.11}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{8}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{8}{subfigure.1.2}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Video encoder block diagram.\relax }}{10}{figure.caption.13}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Motion Vector in Video Codec.\relax }}{12}{figure.caption.15}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Macroblock in Video Encoder.\relax }}{13}{figure.caption.16}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Macroblock (4:2:0).\relax }}{14}{figure.caption.17}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Reference motion vectors in video coding.\relax }}{15}{figure.caption.18}
\contentsline {figure}{\numberline {2.7}{\ignorespaces The example of MV extraction.(a) Test video sequence from recorded camera, (b, c, d) Test video sequence from VIRAT dataset.\relax }}{17}{figure.caption.19}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{17}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{17}{subfigure.7.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{17}{subfigure.7.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{17}{subfigure.7.4}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Smoke detection pipeline: (a) input frame, (b) the foreground subtraction, (c) the blob detection, (d) the smoke candidates classification \relax }}{19}{figure.caption.20}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{19}{subfigure.8.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{19}{subfigure.8.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{19}{subfigure.8.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{19}{subfigure.8.4}
\contentsline {figure}{\numberline {2.9}{\ignorespaces The pipeline of video- based smoke detection algorithm.\relax }}{19}{figure.caption.21}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Architecture of the Alexnet CNN model.\relax }}{21}{figure.caption.22}
\contentsline {figure}{\numberline {2.11}{\ignorespaces CNN based Object Detection Framework Structure.(a) RCNN, (b) Faster-RCNN, (c)Fast-RCNN.\relax }}{22}{figure.caption.23}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{22}{subfigure.11.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{22}{subfigure.11.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{22}{subfigure.11.3}
\contentsline {figure}{\numberline {2.12}{\ignorespaces YOLO Structer.\relax }}{23}{figure.caption.24}
\contentsline {figure}{\numberline {2.13}{\ignorespaces YOLOv3 Network Model.\relax }}{25}{figure.caption.25}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of our proposed edge-to-cloud system.\relax }}{27}{figure.caption.26}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Workflow of the proposed method of moving object detection in compressed domain.\relax }}{29}{figure.caption.27}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Video coding MV extraction from consecutive frames with two different video test sequences.\relax }}{30}{figure.caption.28}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{30}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{30}{subfigure.3.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{30}{subfigure.3.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{30}{subfigure.3.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{30}{subfigure.3.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{30}{subfigure.3.6}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Motion vector of a moving object in different video test sequences: (a, b) our record video, (c, d) Test video in VIRAT\relax }}{31}{figure.caption.29}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{31}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{31}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{31}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{31}{subfigure.4.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Moving objects detection by the proposed method with two different video test sequences:(a,e) MV extraction; (b,f) Apply median filter; (c,g) Clustering MVs; (d,f) Blob detection.\relax }}{33}{figure.caption.30}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{33}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{33}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{33}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{33}{subfigure.5.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{33}{subfigure.5.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{33}{subfigure.5.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{33}{subfigure.5.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{33}{subfigure.5.8}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Motion size based Filtering\relax }}{34}{figure.caption.31}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Object matching method\relax }}{35}{figure.caption.32}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Overview of System Design\relax }}{40}{figure.caption.34}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Testbed: (a) Scenario Setup, (b) The implemendted edge device.\relax }}{41}{figure.caption.35}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{41}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{41}{subfigure.2.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces The ground-truth motion time of our video test sequence.\relax }}{41}{figure.caption.39}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Moving objects detection by the proposed method in different scenarios: (a, b, c, d) human walking; (e, f, g, h) human running; (i, j, k, l) test with a far distance of camera.\relax }}{43}{figure.caption.40}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{43}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{43}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{43}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{43}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{43}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{43}{subfigure.4.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{43}{subfigure.4.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{43}{subfigure.4.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{43}{subfigure.4.9}
\contentsline {subfigure}{\numberline {(j)}{\ignorespaces {}}}{43}{subfigure.4.10}
\contentsline {subfigure}{\numberline {(k)}{\ignorespaces {}}}{43}{subfigure.4.11}
\contentsline {subfigure}{\numberline {(l)}{\ignorespaces {}}}{43}{subfigure.4.12}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Moving objects tracking by the proposed method with different $\alpha $ thresholds: $\alpha $ = 0.25 in (a, b, c), $\alpha $ = 0.4 in (d, e, f) and $\alpha $ = 0.5 in (d, e, f).\relax }}{44}{figure.caption.43}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{44}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{44}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{44}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{44}{subfigure.5.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{44}{subfigure.5.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{44}{subfigure.5.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{44}{subfigure.5.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{44}{subfigure.5.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{44}{subfigure.5.9}
\contentsline {figure}{\numberline {4.6}{\ignorespaces GPU Monitoring with the conventional method and the proposed method ($\alpha $ = 0.25).\relax }}{46}{figure.caption.44}
\contentsline {figure}{\numberline {4.7}{\ignorespaces GPU Monitoring: (a) $\alpha $ = 0.5, (b) $\alpha $ = 0.25, (c) $\alpha $ = 0.75, (d) Ground Truth Motion Chart \relax }}{46}{figure.caption.45}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{46}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{46}{subfigure.7.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{46}{subfigure.7.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{46}{subfigure.7.4}
\contentsline {figure}{\numberline {4.8}{\ignorespaces CPU Monitoring with both the conventional method and the proposed method.\relax }}{47}{figure.caption.46}
\contentsline {figure}{\numberline {4.9}{\ignorespaces CPU Ultilization with different alpha threshold.\relax }}{47}{figure.caption.47}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Network download throughput monitoring with both the conventional method and the proposed method.\relax }}{48}{figure.caption.48}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Download Throughput with different alpha threshold.\relax }}{48}{figure.caption.49}
