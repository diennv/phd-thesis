\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Overall of cloud based video analytics server\relax }}{2}{figure.caption.7}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Video Analytics Implementation, (a) Video management server based implementation, (b) Edge camera based implementation\relax }}{6}{figure.caption.8}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{6}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{6}{subfigure.1.2}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Motion Vector in Video Codec.\relax }}{11}{figure.caption.11}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Reference motion vectors in video coding.\relax }}{11}{figure.caption.12}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of motion vectors extraction.(a) Test video sequence from our recorded video, (b) Test video sequence from VIRAT.\relax }}{13}{figure.caption.13}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{13}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{13}{subfigure.4.2}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Smoke detection process: (a) input image, (b) foreground subtraction, (c) blob detection, (d) smoke classification \relax }}{15}{figure.caption.14}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{15}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{15}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{15}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{15}{subfigure.5.4}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of the proposed edge-to-cloud system model.\relax }}{19}{figure.caption.15}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Workflow of the proposed detection-based tracking approach in compressed domain.\relax }}{21}{figure.caption.16}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Video coding motion vector extraction from consecutive frames with two video test sequences.\relax }}{22}{figure.caption.17}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{22}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{22}{subfigure.3.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{22}{subfigure.3.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{22}{subfigure.3.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{22}{subfigure.3.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{22}{subfigure.3.6}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Motion vector of a moving object in different video test sequences: (a, b) our record video, (c, d) Test video in VIRAT\relax }}{23}{figure.caption.18}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{23}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{23}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{23}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{23}{subfigure.4.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Moving objects detection by the proposed method with two different video test sequences:(a,e) MV extraction; (b,f) Apply median filter; (c,g) Clustering MVs; (d,f) Blob detection.\relax }}{25}{figure.caption.19}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{25}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{25}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{25}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{25}{subfigure.5.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{25}{subfigure.5.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{25}{subfigure.5.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{25}{subfigure.5.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{25}{subfigure.5.8}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Object matching method\relax }}{26}{figure.caption.20}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Overview of System Design\relax }}{30}{figure.caption.22}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Testbed: (a) Scenario Setup, (b) The implemendted edge device.\relax }}{31}{figure.caption.23}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{31}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{31}{subfigure.2.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Moving objects detection by the proposed method in different scenarios: (a, b, c, d) human walking; (e, f, g, h) human running; (i, j, k, l) test with a far distance of camera.\relax }}{33}{figure.caption.27}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{33}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{33}{subfigure.3.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{33}{subfigure.3.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{33}{subfigure.3.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{33}{subfigure.3.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{33}{subfigure.3.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{33}{subfigure.3.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{33}{subfigure.3.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{33}{subfigure.3.9}
\contentsline {subfigure}{\numberline {(j)}{\ignorespaces {}}}{33}{subfigure.3.10}
\contentsline {subfigure}{\numberline {(k)}{\ignorespaces {}}}{33}{subfigure.3.11}
\contentsline {subfigure}{\numberline {(l)}{\ignorespaces {}}}{33}{subfigure.3.12}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Moving objects tracking by the proposed method with different $\alpha $ thresholds: $\alpha $ = 0.25 in (a, b, c), $\alpha $ = 0.4 in (d, e, f) and $\alpha $ = 0.5 in (d, e, f).\relax }}{34}{figure.caption.30}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{34}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{34}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{34}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{34}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{34}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{34}{subfigure.4.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{34}{subfigure.4.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{34}{subfigure.4.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{34}{subfigure.4.9}
\contentsline {figure}{\numberline {4.5}{\ignorespaces GPU Monitoring: (a) With the conventional method, (b) With the proposed method.\relax }}{36}{figure.caption.31}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{36}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{36}{subfigure.5.2}
\contentsline {figure}{\numberline {4.6}{\ignorespaces CPU Monitoring with both the conventional method and the proposed method.\relax }}{36}{figure.caption.32}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{36}{subfigure.6.1}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Network download throughput monitoring with both the conventional method and the proposed method.\relax }}{37}{figure.caption.33}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{37}{subfigure.7.1}
\addvspace {10\p@ }
\addvspace {10\p@ }
