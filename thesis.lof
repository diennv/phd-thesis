\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Surveillance Camera Deployment and Application\relax }}{1}{figure.caption.7}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{1}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{1}{subfigure.1.2}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Overall of cloud based video analytics server\relax }}{2}{figure.caption.8}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Real-time Video Analytics Challenges\relax }}{3}{figure.caption.9}
\contentsline {figure}{\numberline {1.4}{\ignorespaces The motivated system design\relax }}{4}{figure.caption.10}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Video Analytics Implementation, (a) Video management server based implementation, (b) Edge camera based implementation\relax }}{8}{figure.caption.11}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{8}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{8}{subfigure.1.2}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Video encoder block diagram.\relax }}{11}{figure.caption.13}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Motion Vector in Video Codec.\relax }}{13}{figure.caption.15}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Macroblock in Video Encoder.\relax }}{13}{figure.caption.16}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Macroblock (4:2:0).\relax }}{14}{figure.caption.17}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Reference motion vectors in video coding.\relax }}{15}{figure.caption.18}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{15}{subfigure.6.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{15}{subfigure.6.2}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Example of motion vectors extraction.(a) Test video sequence from our recorded video, (b) Test video sequence from VIRAT.\relax }}{17}{figure.caption.19}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{17}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{17}{subfigure.7.2}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Smoke detection process: (a) input image, (b) foreground subtraction, (c) blob detection, (d) smoke classification \relax }}{18}{figure.caption.20}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{18}{subfigure.8.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{18}{subfigure.8.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{18}{subfigure.8.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{18}{subfigure.8.4}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Flow chart of our video- based smoke detection algorithm.\relax }}{19}{figure.caption.21}
\contentsline {figure}{\numberline {2.10}{\ignorespaces CNN based Object Detection Framework Structure.(a) RCNN, (b) Faster-RCNN, (c)Fast-RCNN.\relax }}{20}{figure.caption.22}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{20}{subfigure.10.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{20}{subfigure.10.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{20}{subfigure.10.3}
\contentsline {figure}{\numberline {2.11}{\ignorespaces YOLO Structer.\relax }}{21}{figure.caption.23}
\contentsline {figure}{\numberline {2.12}{\ignorespaces YOLOv3 Network Model.\relax }}{23}{figure.caption.24}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of the proposed edge-to-cloud system model.\relax }}{25}{figure.caption.25}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Workflow of the proposed detection-based tracking approach in compressed domain.\relax }}{27}{figure.caption.26}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Video coding motion vector extraction from consecutive frames with two video test sequences.\relax }}{28}{figure.caption.27}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{28}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{28}{subfigure.3.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{28}{subfigure.3.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{28}{subfigure.3.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{28}{subfigure.3.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{28}{subfigure.3.6}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Motion vector of a moving object in different video test sequences: (a, b) our record video, (c, d) Test video in VIRAT\relax }}{29}{figure.caption.28}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{29}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{29}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{29}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{29}{subfigure.4.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Moving objects detection by the proposed method with two different video test sequences:(a,e) MV extraction; (b,f) Apply median filter; (c,g) Clustering MVs; (d,f) Blob detection.\relax }}{31}{figure.caption.29}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{31}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{31}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{31}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{31}{subfigure.5.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{31}{subfigure.5.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{31}{subfigure.5.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{31}{subfigure.5.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{31}{subfigure.5.8}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Motion size based Filtering\relax }}{32}{figure.caption.30}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Object matching method\relax }}{33}{figure.caption.31}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Overview of System Design\relax }}{38}{figure.caption.33}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Testbed: (a) Scenario Setup, (b) The implemendted edge device.\relax }}{39}{figure.caption.34}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{39}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{39}{subfigure.2.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces The ground-truth motion time of our video test sequence.\relax }}{39}{figure.caption.38}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Moving objects detection by the proposed method in different scenarios: (a, b, c, d) human walking; (e, f, g, h) human running; (i, j, k, l) test with a far distance of camera.\relax }}{41}{figure.caption.39}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{41}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{41}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{41}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{41}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{41}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{41}{subfigure.4.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{41}{subfigure.4.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{41}{subfigure.4.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{41}{subfigure.4.9}
\contentsline {subfigure}{\numberline {(j)}{\ignorespaces {}}}{41}{subfigure.4.10}
\contentsline {subfigure}{\numberline {(k)}{\ignorespaces {}}}{41}{subfigure.4.11}
\contentsline {subfigure}{\numberline {(l)}{\ignorespaces {}}}{41}{subfigure.4.12}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Moving objects tracking by the proposed method with different $\alpha $ thresholds: $\alpha $ = 0.25 in (a, b, c), $\alpha $ = 0.4 in (d, e, f) and $\alpha $ = 0.5 in (d, e, f).\relax }}{42}{figure.caption.42}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{42}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{42}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{42}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{42}{subfigure.5.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{42}{subfigure.5.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{42}{subfigure.5.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{42}{subfigure.5.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{42}{subfigure.5.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{42}{subfigure.5.9}
\contentsline {figure}{\numberline {4.6}{\ignorespaces GPU Monitoring with the conventional method and the proposed method.\relax }}{44}{figure.caption.43}
\contentsline {figure}{\numberline {4.7}{\ignorespaces CPU Monitoring with both the conventional method and the proposed method.\relax }}{44}{figure.caption.44}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{44}{subfigure.7.1}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Network download throughput monitoring with both the conventional method and the proposed method.\relax }}{45}{figure.caption.45}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{45}{subfigure.8.1}
