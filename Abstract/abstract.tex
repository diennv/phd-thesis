% ************************** Thesis Abstract *****************************
% Use `abstract' as an option in the document class to print only the titlepage and the abstract.
%Every academic paper begins with title page. Its structure depends on the chosen formatting style. An abstract follows it. This is an important part that describes thesis utility. It must be short and take 1-2 paragraphs, about 400 words and contain short summary of results, methods, etc. Here are questions to answer in this part:

%What was the reason to write this paper?
%What thesis statement to prove or disprove?
%What were your instruments? (describe main methods of research)
%What did you find out?
%Why are the results important?
\begin{abstract}
Intelligent video analytics systems have come to play an essential role in many fields, including public safety, transportation safety, and many other industry areas, as automated tools for data extracting and analyzing huge datasets such as multiple live video streams transmitted from a large number of cameras. A key characteristic of such systems is that it is critical to perform real-time analytics so as to provide timely actionable alerts on various tasks, activities and conditions. Due to the computation-intensive and bandwidth-intensive nature of these operations, however, video analytics servers may not fulfill the requirements when serving for a large number of cameras simultaneously. To handle these challenges, this dissertation present an edge-computing based system that minimizes transfer of video data from the surveillance camera feeds on a cloud video analytics server. Based on a novel approach of utilizing the information from the encoded bitstream, the edge can achieve low processing complexity of object tracking in surveillance videos and filters non-motion frames from the list of data which will be forwarded to the cloud server. To demonstrate the effectiveness of the approach, we have implemented a video surveillance prototype consisting of edge devices with low computational capacity and a GPU-enabled server. The evaluation results show that our method can efficiently catch the characteristics of the frame and is compatible with the edge-to-cloud platform in terms of accuracy and delay sensitivity. The average processing time of this method is approximately 39 ms/frame with high definition resolution video, which outperforms most of the state of art method. In addition to scenario implementation of the proposed system, the method helps the cloud server reduce 49\% load of GPU, 49\% load of CPU, and 55\% of network traffic while maintaining the accuracy of real-time 18 video analytics event detection.
\end{abstract}
