% ************************** Thesis Abstract *****************************
% Use `abstract' as an option in the document class to print only the titlepage and the abstract.
%Every academic paper begins with title page. Its structure depends on the chosen formatting style. An abstract follows it. This is an important part that describes thesis utility. It must be short and take 1-2 paragraphs, about 400 words and contain short summary of results, methods, etc. Here are questions to answer in this part:

%What was the reason to write this paper?
%What thesis statement to prove or disprove?
%What were your instruments? (describe main methods of research)
%What did you find out?
%Why are the results important?
\begin{abstract}
Intelligent Video Analytics(VA) systems have play an important role in many areas, including public security, transportation safety, and many other industry fields, as automatically tools for data collecting and analyzing big datasets such as multiple live video streams transmitted from many cameras. An important characteristic of these systems is that it is critical and difficult to perform real-time analytics so as to provide timely event alerts on different tasks, activities and conditions. Due to the computation-limitation and bandwidth-limitation nature of these operations, however, video analytics servers may not meet the requirements when serving for a large number of cameras simultaneously. To overcome these challenges, this dissertation present an edge-computing based system that minimizes transfer of video data from the surveillance camera sources to a video analytics server on the cloud. Based on a novel solution of utilizing the information from the encoded bitstream, the edge can achieve low processing complexity of object tracking in surveillance videos and filters non-motion frames from the list of frames which will be forwarded to the cloud server. To demonstrate the effectiveness of the approach, we implemented a video surveillance system consisting of an edge device with low computational capacity and a GPU-enabled server. The evaluation results show that our method can efficiently catch the characteristics of the frame and is compatible with the edge-to-cloud platform in terms of accuracy and delay sensitivity. The average processing time of this method is approximately 39 ms/frame with high definition resolution video, which outperforms most of the state of art method. In addition to scenario implementation of the proposed system, the method helps the cloud server reduce 48\% load of GPU, 48\% load of CPU, and 51\% of network traffic while still maintaining the accuracy of real-time video analytics event alerts.
\end{abstract}
