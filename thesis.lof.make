\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Overall of cloud based video analytics server\relax }}{2}{figure.caption.7}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Video Analytics Implementation, (a) Video management server based implementation, (b) Edge camera based implementation\relax }}{6}{figure.caption.8}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{6}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{6}{subfigure.1.2}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Video encoder block diagram.\relax }}{9}{figure.caption.10}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Motion Vector in Video Codec.\relax }}{11}{figure.caption.12}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Macroblock in Video Encoder.\relax }}{11}{figure.caption.13}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Macroblock (4:2:0).\relax }}{12}{figure.caption.14}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Reference motion vectors in video coding.\relax }}{13}{figure.caption.15}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Example of motion vectors extraction.(a) Test video sequence from our recorded video, (b) Test video sequence from VIRAT.\relax }}{15}{figure.caption.16}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{15}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{15}{subfigure.7.2}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Smoke detection process: (a) input image, (b) foreground subtraction, (c) blob detection, (d) smoke classification \relax }}{16}{figure.caption.17}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{16}{subfigure.8.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{16}{subfigure.8.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{16}{subfigure.8.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{16}{subfigure.8.4}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of the proposed edge-to-cloud system model.\relax }}{21}{figure.caption.18}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Workflow of the proposed detection-based tracking approach in compressed domain.\relax }}{23}{figure.caption.19}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Video coding motion vector extraction from consecutive frames with two video test sequences.\relax }}{24}{figure.caption.20}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{24}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{24}{subfigure.3.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{24}{subfigure.3.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{24}{subfigure.3.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{24}{subfigure.3.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{24}{subfigure.3.6}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Motion vector of a moving object in different video test sequences: (a, b) our record video, (c, d) Test video in VIRAT\relax }}{25}{figure.caption.21}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{25}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{25}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{25}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{25}{subfigure.4.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Moving objects detection by the proposed method with two different video test sequences:(a,e) MV extraction; (b,f) Apply median filter; (c,g) Clustering MVs; (d,f) Blob detection.\relax }}{27}{figure.caption.22}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{27}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{27}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{27}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{27}{subfigure.5.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{27}{subfigure.5.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{27}{subfigure.5.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{27}{subfigure.5.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{27}{subfigure.5.8}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Object matching method\relax }}{28}{figure.caption.23}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Overview of System Design\relax }}{32}{figure.caption.25}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Testbed: (a) Scenario Setup, (b) The implemendted edge device.\relax }}{33}{figure.caption.26}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{33}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{33}{subfigure.2.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Moving objects detection by the proposed method in different scenarios: (a, b, c, d) human walking; (e, f, g, h) human running; (i, j, k, l) test with a far distance of camera.\relax }}{35}{figure.caption.30}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{35}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{35}{subfigure.3.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{35}{subfigure.3.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{35}{subfigure.3.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{35}{subfigure.3.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{35}{subfigure.3.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{35}{subfigure.3.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{35}{subfigure.3.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{35}{subfigure.3.9}
\contentsline {subfigure}{\numberline {(j)}{\ignorespaces {}}}{35}{subfigure.3.10}
\contentsline {subfigure}{\numberline {(k)}{\ignorespaces {}}}{35}{subfigure.3.11}
\contentsline {subfigure}{\numberline {(l)}{\ignorespaces {}}}{35}{subfigure.3.12}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Moving objects tracking by the proposed method with different $\alpha $ thresholds: $\alpha $ = 0.25 in (a, b, c), $\alpha $ = 0.4 in (d, e, f) and $\alpha $ = 0.5 in (d, e, f).\relax }}{36}{figure.caption.33}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{36}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{36}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{36}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{36}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{36}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{36}{subfigure.4.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{36}{subfigure.4.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{36}{subfigure.4.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {}}}{36}{subfigure.4.9}
\contentsline {figure}{\numberline {4.5}{\ignorespaces GPU Monitoring: (a) With the conventional method, (b) With the proposed method.\relax }}{38}{figure.caption.34}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{38}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{38}{subfigure.5.2}
\contentsline {figure}{\numberline {4.6}{\ignorespaces CPU Monitoring with both the conventional method and the proposed method.\relax }}{38}{figure.caption.35}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{38}{subfigure.6.1}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Network download throughput monitoring with both the conventional method and the proposed method.\relax }}{39}{figure.caption.36}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{39}{subfigure.7.1}
\addvspace {10\p@ }
\addvspace {10\p@ }
